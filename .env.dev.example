# =============================================================================
# PoC Demo Configuration - Environment Variables
# =============================================================================
# Copy this file to .env and update the values according to your setup.
# 
# Usage:
#   cp .env.dev.example .env
#   # Edit .env with your actual values
#
# =============================================================================

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
APP_NAME=jj-ai-avatar-livekit-agent-poc
LOG_LEVEL=INFO
DEBUG=false

# -----------------------------------------------------------------------------
# RabbitMQ Connection Settings
# -----------------------------------------------------------------------------
# RabbitMQ server connection details
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest
RABBITMQ_VHOST=/
RABBITMQ_QUEUE=talking_face_input
# Optional: Exchange and routing key (if using exchange-based routing)
# RABBITMQ_EXCHANGE=
# RABBITMQ_ROUTING_KEY=

# -----------------------------------------------------------------------------
# RTMP Streaming Settings
# -----------------------------------------------------------------------------
# RTMP output URL (REQUIRED - must be set)
# Example: rtmp://your-server.com/live/stream_key
RTMP_URL=rtmp://localhost:1935/live/stream_key

# Video encoding settings
RTMP_RESOLUTION=1280x720
RTMP_FPS=30
RTMP_BITRATE=2000k

# Audio encoding settings
RTMP_AUDIO_BITRATE=128k
RTMP_AUDIO_SAMPLE_RATE=44100

# -----------------------------------------------------------------------------
# Static Video Settings (Idle State)
# -----------------------------------------------------------------------------
# Path to static image or video file for idle/default state
# Can be a PNG/JPG image or MP4 video file
STATIC_VIDEO_PATH=./assets/default_avatar.png
# Loop static video if it's a video file (true/false)
STATIC_VIDEO_LOOP=true
# Optional: Override FPS for static video (uses RTMP_FPS if not set)
# STATIC_VIDEO_FPS=30

# -----------------------------------------------------------------------------
# Talking Face Provider Settings
# -----------------------------------------------------------------------------
# Provider type: 'api' for external API, 'local' for local AI inference
TALKING_FACE_PROVIDER=local

# Model type: 'musetalk' (primary), 'mimictalk', or 'synctalk' (backup models)
TALKING_FACE_MODEL=musetalk

# -----------------------------------------------------------------------------
# Talking Face API Settings (for external API provider)
# -----------------------------------------------------------------------------
# Only needed if TALKING_FACE_PROVIDER=api
# TALKING_FACE_API_URL=https://api.example.com
# TALKING_FACE_API_KEY=your-api-key-here
# TALKING_FACE_API_AVATAR_ID=avatar-123
# TALKING_FACE_API_TIMEOUT=30
# TALKING_FACE_API_MAX_RETRIES=3

# -----------------------------------------------------------------------------
# MuseTalk Settings (Primary Model - Local AI Inference)
# -----------------------------------------------------------------------------
# Path to MuseTalk model checkpoints
# Download models from: https://github.com/OpenTalker/MuseTalk
MUSETALK_CHECKPOINT_PATH=./models/musetalk

# Default avatar image path (for image-to-video generation)
MUSETALK_AVATAR_IMAGE=./assets/avatar.png

# Optional: Video input for video-to-video generation
# If set, MuseTalk will use video input instead of image input
# MUSETALK_AVATAR_VIDEO=./assets/avatar_video.mp4

# Device for inference: 'cuda' (GPU) or 'cpu'
MUSETALK_DEVICE=cuda

# Inference batch size (typically 1 for real-time streaming)
MUSETALK_BATCH_SIZE=1

# Optional: Output FPS (uses RTMP_FPS if not set)
# MUSETALK_FPS=30

# -----------------------------------------------------------------------------
# MimicTalk Settings (Backup Model - Post-PoC Evaluation)
# -----------------------------------------------------------------------------
# Path to MimicTalk model checkpoints
# Download models from: https://github.com/yerfor/MimicTalk
# MIMICTALK_CHECKPOINT_PATH=./models/mimictalk

# Identity image for MimicTalk (requires training per identity)
# MIMICTALK_AVATAR_IMAGE=./assets/avatar.png

# Device for inference: 'cuda' (GPU) or 'cpu'
# MIMICTALK_DEVICE=cuda

# Inference batch size
# MIMICTALK_BATCH_SIZE=1

# -----------------------------------------------------------------------------
# SyncTalk Settings (Backup Model - Post-PoC Evaluation)
# -----------------------------------------------------------------------------
# Path to SyncTalk model checkpoints
# Download models from: https://github.com/ZiqiaoPeng/SyncTalk
# SYNCTALK_CHECKPOINT_PATH=./models/synctalk

# SyncTalk workspace path (for trained models)
# SYNCTALK_WORKSPACE_PATH=./models/synctalk/workspace

# Device for inference: 'cuda' (GPU) or 'cpu'
# SYNCTALK_DEVICE=cuda

# Inference batch size
# SYNCTALK_BATCH_SIZE=1

# -----------------------------------------------------------------------------
# FFmpeg Settings
# -----------------------------------------------------------------------------
# FFmpeg executable path (use 'ffmpeg' if in PATH, or full path)
FFMPEG_PATH=ffmpeg

# FFmpeg encoding preset: 'ultrafast', 'fast', 'medium', 'slow'
# Use 'ultrafast' for low latency streaming
FFMPEG_PRESET=ultrafast

# FFmpeg encoding tune: 'zerolatency' for low latency streaming
FFMPEG_TUNE=zerolatency

# GOP (Group of Pictures) size
FFMPEG_GOP_SIZE=50

# Output pixel format
FFMPEG_PIXEL_FORMAT=yuv420p

# =============================================================================
# Notes
# =============================================================================
#
# 1. RTMP_URL is REQUIRED - the application will not start without it.
#
# 2. For local AI inference (MuseTalk):
#    - Ensure you have a compatible NVIDIA GPU with CUDA support
#    - Install PyTorch with CUDA: https://pytorch.org/get-started/locally/
#    - Download MuseTalk models and place them in MUSETALK_CHECKPOINT_PATH
#    - Set MUSETALK_DEVICE=cuda for GPU acceleration
#
# 3. For API-based talking face:
#    - Set TALKING_FACE_PROVIDER=api
#    - Configure TALKING_FACE_API_* settings
#    - Ensure you have valid API credentials
#
# 4. Static video:
#    - Can use a static image (PNG/JPG) or a looping video (MP4)
#    - If using a video, set STATIC_VIDEO_LOOP=true
#    - The static video streams continuously when no messages are being processed
#
# 5. RabbitMQ:
#    - Default credentials (guest/guest) work for local development
#    - For production, use secure credentials
#    - Ensure RabbitMQ server is running before starting the application
#
# =============================================================================
